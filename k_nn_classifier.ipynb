{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "k-nn-classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWP2UXUBnJW0/X6Jr9aEwP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsdysw/knn-classifier/blob/master/k_nn_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "4cyzv11STyJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "CUnRTuxuiaqg"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read dataset\n",
        "feature vector X = {f1, f2, f3, f4, f5, f6}\n",
        "\n",
        "class vector C = {\"satisfied\", \"unsatisfied\"}"
      ],
      "metadata": {
        "id": "7RUz0nvMo0IH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hLaFfcVnuff",
        "outputId": "0b0e5017-0093-4526-b31a-ac4482607d3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples of dataset : \n",
            " [[40 2 1 86872 25 9 'unsatisfied']\n",
            " [40 2 1 259323 54 10 'satisfied']\n",
            " [40 2 1 256813 43 14 'satisfied']]\n"
          ]
        }
      ],
      "source": [
        "# load satisfaction_data.csv from the local path\n",
        "directory_data = './'\n",
        "filename_data = 'satisfaction_data.csv'\n",
        "df = pd.read_csv(os.path.join(directory_data, filename_data), header=None)\n",
        "dataset = df.to_numpy() # pandas dataframe -> numpy array\n",
        "\n",
        "print(\"Examples of dataset : \\n\", dataset[0:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate 10 different train/test dataset pairs randomly\n",
        "train data : test data = 9 : 1"
      ],
      "metadata": {
        "id": "fhf8s7M2D9bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fold_size = int(len(dataset) / 10)\n",
        "fold_num = 10\n",
        "\n",
        "X_dataset = dataset[:,:6]\n",
        "y_dataset = dataset[:,6]\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for i in range(fold_num):\n",
        "    X_test.append(X_dataset[i*fold_size:(i+1)*fold_size])\n",
        "    y_test.append(y_dataset[i*fold_size:(i+1)*fold_size])\n",
        "\n",
        "    xa = X_dataset[:i*fold_size]\n",
        "    xb = X_dataset[(i+1)*fold_size:]\n",
        "\n",
        "    ya = y_dataset[:i*fold_size]\n",
        "    yb = y_dataset[(i+1)*fold_size:]\n",
        "\n",
        "    X_train.append(np.concatenate((xa,xb)))\n",
        "    y_train.append(np.concatenate((ya,yb)))\n",
        "\n",
        "\n",
        "# print(\"Shape of X_test\", X_test[9].shape)\n",
        "# print(\"Shape of y_test\", y_test[9].shape)\n",
        "\n",
        "# print(\"Shape of X_train\", X_train[9].shape)\n",
        "# print(\"Shape of y_train\", y_train[9].shape)"
      ],
      "metadata": {
        "id": "W0aBRVFwEEHs"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing (normalize)"
      ],
      "metadata": {
        "id": "C40EydrXi8kS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_means = []\n",
        "col_std = []\n",
        "\n",
        "for i in range(fold_num):\n",
        "    col_means.append(X_train[i].sum(axis = 0) / len(X_train[i]))\n",
        "    col_std.append(np.std(X_train[i], dtype=np.float64, axis = 0))\n",
        "    \n",
        "    normalized_train_data = (X_train[i] - col_means[i])/col_std[i]\n",
        "    X_train[i] = normalized_train_data\n",
        "\n",
        "    normalized_test_data = (X_test[i] - col_means[i])/col_std[i]\n",
        "    X_test[i] = normalized_test_data\n",
        "\n",
        "print(\"Examples of normalized train dataset : \\n\", X_train[i][0:2])\n",
        "print(\"Examples of normalized test dataset : \\n\", X_test[i][0:2])"
      ],
      "metadata": {
        "id": "skLWq6B1i7dv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9c0dbbb-ed90-41f6-f80a-cb06d0353c86"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples of normalized train dataset : \n",
            " [[-0.2666224404400283 -0.31300994728093356 -0.3067523904747627\n",
            "  -0.9654140175900487 -1.1204620079779688 -0.5308974550386716]\n",
            " [-0.2666224404400283 -0.31300994728093356 -0.3067523904747627\n",
            "  0.7326949552864844 1.1328335502574762 -0.12397554264316428]]\n",
            "Examples of normalized test dataset : \n",
            " [[-0.8577094026190303 -1.1899249746827711 -2.077612887121886\n",
            "  -1.3669511945038344 0.2004353882290163 1.0967901945433576]\n",
            " [0.5777875055299745 1.4408201075227416 -0.3067523904747627\n",
            "  -0.43912637487802 1.3659330907645912 -0.5308974550386716]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# kNN model\n",
        "distance between two data is defined as Euclidean(L2 norm)"
      ],
      "metadata": {
        "id": "ulJwjUUH8QO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KNN:\n",
        "  def __init__(self, k):\n",
        "    self.k = k\n",
        "  \n",
        "  def fit(self, X, y):\n",
        "    self.X_train = X\n",
        "    self.y_train = y\n",
        "\n",
        "  # distance\n",
        "  def distance(self, data1, data2) :\n",
        "    sub = data1 - data2\n",
        "    dis = np.sum(np.square(sub)) ** 0.5\n",
        "    # print(\"data1 : \", data1)\n",
        "    # print(\"data2 : \", data2)\n",
        "    # print(\"sub\", sub)\n",
        "    # print(\"dis\", dis)\n",
        "    return dis\n",
        "\n",
        "\n",
        "  def predict(self, _X_test):\n",
        "    final_output = []\n",
        "\n",
        "    for i in range(len(_X_test)):\n",
        "        if i % 300 == 0 :\n",
        "          print(\"   Loading : \", i/len(_X_test)*100, \"%\")\n",
        "\n",
        "        d = []\n",
        "        votes = []\n",
        "\n",
        "        for j in range(len(self.X_train)):\n",
        "            # get distance with every data samples\n",
        "            dist = self.distance(_X_test[i] , self.X_train[j])\n",
        "            d.append([dist, j])\n",
        "        \n",
        "        d.sort()\n",
        "        d = d[0:self.k]\n",
        "\n",
        "        # vote\n",
        "        for d, j in d:\n",
        "            votes.append(self.y_train[j])  \n",
        "        ans = Counter(votes).most_common(1)[0][0]\n",
        "        final_output.append(ans)\n",
        "      \n",
        "    return final_output\n"
      ],
      "metadata": {
        "id": "NxP3eNab8PYG"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict satisfaction with 10 dataset pairs"
      ],
      "metadata": {
        "id": "bfASzFDaAqnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set k-NN model\n",
        "window_size = 5\n",
        "clf = KNN(window_size)\n",
        "\n",
        "prediction_arr = []\n",
        "\n",
        "for i in range(fold_num):\n",
        "    print(\"Predict with train/test pair \", i)\n",
        "\n",
        "    clf.fit(X_train[i], y_train[i])\n",
        "    \n",
        "    # predict \n",
        "    prediction = clf.predict(X_test[i])\n",
        "    prediction_arr = np.concatenate((prediction_arr,prediction))\n",
        "    \n",
        "    ground_truth = y_test[i]\n",
        "    # print(prediction)\n",
        "    # print(ground_truth)\n",
        "    # prediction loss\n",
        "    accuracy_score = np.sum(prediction == ground_truth) / len(ground_truth) \n",
        "    print(\"       Accuracy_score : \", accuracy_score)\n",
        "\n",
        "\n",
        "# export preiction result .csv \n",
        "df = pd.DataFrame(X_dataset)\n",
        "df.insert(6,\"class\" ,prediction_arr)\n",
        "df.to_csv(r'./20174089.csv', index = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GDXNt7bcztcr",
        "outputId": "ea960547-4d6c-4b32-9564-600ed60de14b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict with train/test pair  0\n",
            "   Loading :  0.0 %\n",
            "   Loading :  15.0 %\n",
            "   Loading :  30.0 %\n",
            "   Loading :  45.0 %\n",
            "   Loading :  60.0 %\n",
            "   Loading :  75.0 %\n",
            "   Loading :  90.0 %\n",
            "       Accuracy_score :  0.753\n",
            "Predict with train/test pair  1\n",
            "   Loading :  0.0 %\n",
            "   Loading :  15.0 %\n",
            "   Loading :  30.0 %\n",
            "   Loading :  45.0 %\n",
            "   Loading :  60.0 %\n",
            "   Loading :  75.0 %\n",
            "   Loading :  90.0 %\n",
            "       Accuracy_score :  0.749\n",
            "Predict with train/test pair  2\n",
            "   Loading :  0.0 %\n",
            "   Loading :  15.0 %\n",
            "   Loading :  30.0 %\n",
            "   Loading :  45.0 %\n",
            "   Loading :  60.0 %\n",
            "   Loading :  75.0 %\n",
            "   Loading :  90.0 %\n",
            "       Accuracy_score :  0.7505\n",
            "Predict with train/test pair  3\n",
            "   Loading :  0.0 %\n",
            "   Loading :  15.0 %\n",
            "   Loading :  30.0 %\n",
            "   Loading :  45.0 %\n",
            "   Loading :  60.0 %\n",
            "   Loading :  75.0 %\n",
            "   Loading :  90.0 %\n",
            "       Accuracy_score :  0.736\n",
            "Predict with train/test pair  4\n",
            "   Loading :  0.0 %\n",
            "   Loading :  15.0 %\n",
            "   Loading :  30.0 %\n",
            "   Loading :  45.0 %\n",
            "   Loading :  60.0 %\n",
            "   Loading :  75.0 %\n",
            "   Loading :  90.0 %\n",
            "       Accuracy_score :  0.75\n",
            "Predict with train/test pair  5\n",
            "   Loading :  0.0 %\n",
            "   Loading :  15.0 %\n",
            "   Loading :  30.0 %\n",
            "   Loading :  45.0 %\n",
            "   Loading :  60.0 %\n",
            "   Loading :  75.0 %\n",
            "   Loading :  90.0 %\n",
            "       Accuracy_score :  0.7605\n",
            "Predict with train/test pair  6\n",
            "   Loading :  0.0 %\n",
            "   Loading :  15.0 %\n",
            "   Loading :  30.0 %\n",
            "   Loading :  45.0 %\n",
            "   Loading :  60.0 %\n",
            "   Loading :  75.0 %\n",
            "   Loading :  90.0 %\n",
            "       Accuracy_score :  0.757\n",
            "Predict with train/test pair  7\n",
            "   Loading :  0.0 %\n",
            "   Loading :  15.0 %\n",
            "   Loading :  30.0 %\n",
            "   Loading :  45.0 %\n",
            "   Loading :  60.0 %\n",
            "   Loading :  75.0 %\n",
            "   Loading :  90.0 %\n",
            "       Accuracy_score :  0.75\n",
            "Predict with train/test pair  8\n",
            "   Loading :  0.0 %\n",
            "   Loading :  15.0 %\n",
            "   Loading :  30.0 %\n",
            "   Loading :  45.0 %\n",
            "   Loading :  60.0 %\n",
            "   Loading :  75.0 %\n",
            "   Loading :  90.0 %\n",
            "       Accuracy_score :  0.7445\n",
            "Predict with train/test pair  9\n",
            "   Loading :  0.0 %\n",
            "   Loading :  15.0 %\n",
            "   Loading :  30.0 %\n",
            "   Loading :  45.0 %\n",
            "   Loading :  60.0 %\n",
            "   Loading :  75.0 %\n",
            "   Loading :  90.0 %\n",
            "       Accuracy_score :  0.759\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-c2a004ca0695>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# export preiction result .csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"class\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mprediction_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'./20174089.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   4416\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc must be int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4418\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4419\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4509\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         raise ValueError(\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0;34m\"does not match length of index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (10) does not match length of index (20000)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_accuracy_score = np.sum(prediction_arr == y_dataset) / len(prediction_arr) \n",
        "print(\"Fianl accuracy_score : \", final_accuracy_score)"
      ],
      "metadata": {
        "id": "OPoMuFzVcDM-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}