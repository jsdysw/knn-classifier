{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "k-nn-classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWg0wtTXepJEc9Fmb0Mu1s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsdysw/knn-classifier/blob/master/k_nn_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "CUnRTuxuiaqg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read dataset\n",
        "feature vector X = {f1, f2, f3, f4, f5, f6}\n",
        "\n",
        "class vector C = {\"satisfied\", \"unsatisfied\"}"
      ],
      "metadata": {
        "id": "7RUz0nvMo0IH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hLaFfcVnuff",
        "outputId": "ad22a5e0-71d2-4133-82b8-0ce923b3b2be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples of dataset : \n",
            " [[40 2 1 86872 25 9 'unsatisfied']\n",
            " [40 2 1 259323 54 10 'satisfied']\n",
            " [40 2 1 256813 43 14 'satisfied']]\n"
          ]
        }
      ],
      "source": [
        "# load satisfaction_data.csv from the local path\n",
        "directory_data = './'\n",
        "filename_data = 'satisfaction_data.csv'\n",
        "df = pd.read_csv(os.path.join(directory_data, filename_data), header=None)\n",
        "dataset = df.to_numpy() # pandas dataframe -> numpy array\n",
        "\n",
        "print(\"Examples of dataset : \\n\", dataset[0:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data processing (normalize)"
      ],
      "metadata": {
        "id": "C40EydrXi8kS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tot_data = dataset[:,:6]\n",
        "label = dataset[:,6]\n",
        "col_mean = tot_data.sum(axis = 0) / len(tot_data)\n",
        "col_std = np.std(tot_data, dtype=np.float64, axis = 0)\n",
        "\n",
        "normalized_tot_data = (tot_data - col_mean)/col_std\n",
        "\n",
        "dataset[:,:6] = normalized_tot_data\n",
        "\n",
        "# print(\"Examples of dataset : \\n\", dataset[0:3])"
      ],
      "metadata": {
        "id": "skLWq6B1i7dv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate 10 different train/test dataset pairs randomly\n",
        "train data : test data = 9 : 1"
      ],
      "metadata": {
        "id": "fhf8s7M2D9bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_dataset = dataset[:,:6]\n",
        "y_dataset = dataset[:,6]\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for i in range(10):\n",
        "    xtrain, xtest, ytrain, ytest  = train_test_split(X_dataset, y_dataset, test_size=0.1, stratify=y_dataset)\n",
        "    X_train.append(xtrain)\n",
        "    y_train.append(ytrain)\n",
        "    X_test.append(xtest)\n",
        "    y_test.append(ytest)\n",
        "\n",
        "# print(\"Examples of dataset : \\n\", X_test[0][0:10])"
      ],
      "metadata": {
        "id": "W0aBRVFwEEHs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# kNN model\n",
        "distance between two data is defined as Euclidean(L2 norm)"
      ],
      "metadata": {
        "id": "ulJwjUUH8QO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KNN:\n",
        "  def __init__(self, k):\n",
        "    self.k = k\n",
        "  \n",
        "  def fit(self, X, y):\n",
        "    self.X_train = X\n",
        "    self.y_train = y\n",
        "\n",
        "  # data\n",
        "  def distance(self, data1, data2) :\n",
        "    sub = data1 - data2\n",
        "    dis = np.sum(np.square(sub)) ** 0.5\n",
        "    # print(\"data1 : \", data1)\n",
        "    # print(\"data2 : \", data2)\n",
        "    # print(\"sub\", sub)\n",
        "    # print(\"dis\", dis)\n",
        "    return dis\n",
        "\n",
        "\n",
        "  def predict(self, _X_test):\n",
        "    final_output = []\n",
        "\n",
        "    for i in range(len(_X_test)):\n",
        "        if i % 700 == 0 :\n",
        "          print(\"   Loading : \", i/len(_X_test))\n",
        "\n",
        "        d = []\n",
        "        votes = []\n",
        "\n",
        "        for j in range(len(self.X_train)):\n",
        "            # get distance with every data samples\n",
        "            dist = self.distance(_X_test[i] , self.X_train[j])\n",
        "            d.append([dist, j])\n",
        "        \n",
        "        d.sort()\n",
        "        d = d[0:self.k]\n",
        "\n",
        "        # vote\n",
        "        for d, j in d:\n",
        "            votes.append(self.y_train[j])  \n",
        "        ans = Counter(votes).most_common(1)[0][0]\n",
        "        final_output.append(ans)\n",
        "      \n",
        "    return final_output\n"
      ],
      "metadata": {
        "id": "NxP3eNab8PYG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict satisfaction with 10 dataset pairs"
      ],
      "metadata": {
        "id": "bfASzFDaAqnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set k-NN model\n",
        "window_size = 5\n",
        "clf = KNN(window_size)\n",
        "\n",
        "num_of_test_input = 2000\n",
        "num_of_datapairs = 10\n",
        "\n",
        "for i in range(num_of_datapairs):\n",
        "    print(\"Predict with train/test pair# : \", i)\n",
        "\n",
        "    clf.fit(X_train[i][0:], y_train[i][0:])\n",
        "    \n",
        "    # predict \n",
        "    prediction = clf.predict(X_test[i][0:num_of_test_input])\n",
        "        \n",
        "    ground_truth = y_test[i][0:num_of_test_input]\n",
        "    # print(prediction)\n",
        "    # print(ground_truth)\n",
        "    # prediction loss\n",
        "    accuracy_score = np.sum(prediction == ground_truth) / len(ground_truth) \n",
        "    print(\"       Accuracy_score : \", accuracy_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "GDXNt7bcztcr",
        "outputId": "8adbeb84-4a28-47f5-cc73-952d30bfb427"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict with train/test pair# :  0\n",
            "   Loading :  0.0\n",
            "   Loading :  0.1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-ed22c70e6bda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_of_test_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mground_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_of_test_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-5252e425a327>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, _X_test)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# get distance with every data samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_X_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-5252e425a327>\u001b[0m in \u001b[0;36mdistance\u001b[0;34m(self, data1, data2)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m# print(\"data1 : \", data1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# print(\"data2 : \", data2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2259\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2260\u001b[0;31m                           initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # set k-NN model\n",
        "# # window_size = 5\n",
        "# # clf = KNN(window_size)\n",
        "\n",
        "# num_of_test_input = 2000\n",
        "# num_of_datapairs = 10\n",
        "\n",
        "# for i in range(num_of_datapairs):\n",
        "#     accuracy = []\n",
        "    \n",
        "#     for ws in range(10):\n",
        "#         window_size = 2*ws + 1\n",
        "#         clf = KNN(window_size)\n",
        "        \n",
        "#         clf.fit(X_train[i][0:], y_train[i][0:])\n",
        "\n",
        "#         # predict \n",
        "#         prediction = clf.predict(X_test[i][0:num_of_test_input])\n",
        "        \n",
        "#         ground_truth = y_test[i][0:num_of_test_input]\n",
        "#         # print(prediction)\n",
        "#         # print(ground_truth)\n",
        "#         # prediction loss\n",
        "#         accuracy_score = np.sum(prediction == ground_truth) / len(ground_truth) \n",
        "#         accuracy.append(accuracy_score)\n",
        "#         # print(\"Accuracy_score : \", accuracy_score)\n",
        "        \n",
        "#     # plot graph\n",
        "#     plt.figure(figsize=(10,8))\n",
        "#     plt.title('accurracy with data pair#')\n",
        "#     plt.xlabel('window size')\n",
        "#     plt.ylabel('accurracy')\n",
        "#     plt.plot(accuracy)"
      ],
      "metadata": {
        "id": "gjb5wb57s6-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For additional prediction test"
      ],
      "metadata": {
        "id": "HV1JVtkA_S1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "####################################################\n",
        "# load train data\n",
        "####################################################\n",
        "directory_data = './'\n",
        "filename_data = 'satisfaction_data.csv'\n",
        "train_dataset = df.to_numpy() # pandas dataframe -> numpy array\n",
        "\n",
        "# get mean and std of train data and normalize\n",
        "tot_data = train_dataset[:,:6]\n",
        "label = train_dataset[:,6]\n",
        "col_mean = tot_data.sum(axis = 0) / len(tot_data)\n",
        "col_std = np.std(tot_data, dtype=np.float64, axis = 0)\n",
        "\n",
        "normalized_tot_data = (tot_data - col_mean)/col_std\n",
        "\n",
        "train_dataset[:,:6] = normalized_tot_data\n",
        "\n",
        "print(\"Shape of train dataset : \", train_dataset.shape)\n",
        "print(\"Mean of train dataset : \", col_mean)\n",
        "print(\"Std of train dataset : \", col_std)\n",
        "print(\"Examples of normalized train dataset : \\n\", train_dataset[0:3])\n",
        "\n",
        "# split feature and label\n",
        "X_train = train_dataset[:,:6]\n",
        "y_train = train_dataset[:,6]\n",
        "\n",
        "####################################################\n",
        "# load test data\n",
        "####################################################\n",
        "filename_data = 'test_satisfaction_data.csv'\n",
        "df = pd.read_csv(os.path.join(directory_data, filename_data), header=None)\n",
        "train_dataset = df.to_numpy() # pandas dataframe -> numpy array\n",
        "\n",
        "print(\"Shape of test dataset : \", train_dataset.shape)\n",
        "\n",
        "# normalizae test dataset\n",
        "# split feature and label\n",
        "X_test = train_dataset[:,:6]\n",
        "y_test = train_dataset[:,6]\n",
        "normalized_tot_data = (tot_data - col_mean)/col_std\n",
        "\n",
        "X_test = normalized_tot_data\n",
        "print(\"Examples of normalized dataset : \\n\", X_test[0:3])\n",
        "\n",
        "\n",
        "# set k-NN model\n",
        "window_size = 5\n",
        "clf = KNN(window_size)\n",
        "clf.fit(X_train[0:], y_train[0:])\n",
        "\n",
        "# predict \n",
        "prediction = clf.predict(X_test[0:])\n",
        "\n",
        "# prediction loss\n",
        "ground_truth = y_test[0:]\n",
        "accuracy_score = np.sum(prediction == ground_truth) / len(ground_truth) \n",
        "\n",
        "print(\"Additional test accuracy score : \", accuracy_score)  "
      ],
      "metadata": {
        "id": "XXJ0fcXZs5T9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}